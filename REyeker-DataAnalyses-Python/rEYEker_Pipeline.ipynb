{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# lib for regex\n",
    "import re\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker\n",
    "\n",
    "# for t testing\n",
    "from scipy import stats\n",
    "\n",
    "# lib for better plotting\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "\n",
    "# lib for differ calculation\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path = r'./Book4.xlsx'\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable_array = ['TR20_01', 'TI20_01', 'BR20_01', 'BI20_01']\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_names = ['TR_FIB', 'TI_FIB', 'BR_FIB', 'BI_FIB']\n",
    "\n",
    "# columns with time data of visual stimulus\n",
    "config_time_variable_array = []\n",
    "\n",
    "# columns with the given answers of the studen\n",
    "config_answer_variable_array = ['TR10_01', 'TI10_01', 'BR10_01', 'BI10_01']\n",
    "\n",
    "# regex pattern for correct answer\n",
    "config_answer_pattern_array = ['2', '2','2','2']\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable_array = ['TIME042', 'TIME008', 'TIME059', 'TIME023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "config_reyeker_settings_path = \"data/example.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for saving images </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "config_image_path_array = ['images/TR/TR_Fibonacci.png',\n",
    "               'images/TI/TI_Fibonacci.png',\n",
    "               'images/BR/BR_Fibonacci.png',\n",
    "               'images/BI/BI_Fibonacci.png']\n",
    "\n",
    "# where to save to heatmaps and sequence diagrams\n",
    "config_folder_prefix_array = [\n",
    "    'TR/',\n",
    "    'TI/',\n",
    "    'BR/',\n",
    "    'BI/']\n",
    "\n",
    "# used for saving the heatmaps and sequence diagrams\n",
    "config_image_prefix_array = [\n",
    "    'TR_Fibonacci_',\n",
    "    'TI_Fibonacci_',\n",
    "    'BR_Fibonacci_',\n",
    "    'BI_Fibonacci_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for Code Flow data import</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel data in data/code_flow\n",
    "config_code_flow_datasheet_array = ['TR_Fibonacci.xlsx',\n",
    "                  'TI_Fibonacci.xlsx',\n",
    "                  'BR_Fibonacci.xlsx',\n",
    "                  'BI_Fibonacci.xlsx']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuration for aoi data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel data in data/aoi_categorized\n",
    "config_aoi_datasheet_array = ['AOI_TR_Fibonacci.xlsx',\n",
    "                  'AOI_TI_Fibonacci.xlsx',\n",
    "                  'AOI_BR_Fibonacci.xlsx',\n",
    "                  'AOI_BI_Fibonacci.xlsx']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for alpha value for t-test </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence needed for t test\n",
    "config_alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the columns and create dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns_array = []\n",
    "\n",
    "# create all dataframe headers\n",
    "for i in range(len(config_visual_stimulus_variable_array)):\n",
    "    tmp_list = []\n",
    "    tmp_list.append(config_visual_stimulus_variable_array[i])\n",
    "    \n",
    "    if len(config_time_variable_array) != 0:\n",
    "        tmp_list.append(config_time_variable_array[i])\n",
    "\n",
    "    tmp_list.append(config_answer_variable_array[i])\n",
    "    tmp_list.append(config_response_time_variable_array[i])\n",
    "    needed_columns_array.append(tmp_list)\n",
    "\n",
    "df_array = []\n",
    "raw = pd.read_excel(config_datasheet_path)\n",
    "\n",
    "# read all dataframes\n",
    "for data_set in needed_columns_array:\n",
    "    dataframe = pd.DataFrame(raw, columns = data_set)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    dataframe = dataframe.dropna()\n",
    "    df_array.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Splitting Dataframes in right and wrong answers.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_array_right = []\n",
    "df_array_wrong = []\n",
    "\n",
    "# iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    right_answer_pattern = config_answer_pattern_array[idx]\n",
    "    regex = re.compile(right_answer_pattern)\n",
    "    answer_field = config_answer_variable_array[idx]\n",
    "    \n",
    "    dataframe_right = pd.DataFrame(columns = needed_columns_array[idx])\n",
    "    dataframe_wrong = pd.DataFrame(columns = needed_columns_array[idx])\n",
    "    \n",
    "    # iter over every row and check if the result is rightr\n",
    "    for _idx, row  in dataframe.iterrows():\n",
    "        result = regex.match(str(row[answer_field]))\n",
    "        if result is not None:\n",
    "            dataframe_right = dataframe_right.append(row)\n",
    "        else:\n",
    "            dataframe_wrong = dataframe_wrong.append(row)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_array_right.append(dataframe_right)\n",
    "    df_array_wrong.append(dataframe_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove Outliers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_array = []\n",
    "tmp_df_array_wrong = []\n",
    "\n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(df_array_right):\n",
    "\n",
    "    data = dataframe[config_response_time_variable_array[idx]]\n",
    "    cleared_dataframe = None\n",
    "    if len(data) == 1:\n",
    "        cleared_dataframe = dataframe\n",
    "    else:\n",
    "        cleared_dataframe = dataframe[(np.abs(stats.zscore(data.astype(float))) < 3)]\n",
    "    tmp_df_array.append(cleared_dataframe)\n",
    "    \n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(df_array_wrong):\n",
    "    data = dataframe[config_response_time_variable_array[idx]]\n",
    "    cleared_dataframe = dataframe[data.between(data.quantile(.15), data.quantile(0.85))]\n",
    "    tmp_df_array_wrong.append(cleared_dataframe)\n",
    "    \n",
    "df_array = tmp_df_array\n",
    "df_array_wong = tmp_df_array_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(config_reyeker_settings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "\n",
    "# read in every image\n",
    "for image_path in config_image_path_array:\n",
    "    img = rEYEker.load_image(image_path)\n",
    "    image_array.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    visual_stimulus_array = []\n",
    "    visual_stimulus_row = config_visual_stimulus_variable_array[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[visual_stimulus_row]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "        \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            coordinate = coordinate_str.split(\"-\")\n",
    "            coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "            coordinates.append(coordinate)\n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_data_matrix = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    if len(config_time_variable_array) <= idx:\n",
    "        break\n",
    "    time_measurements = []\n",
    "    time_measurement_row = config_time_variable_array[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[time_measurement_row]\n",
    "        data_str = data_str.strip()\n",
    "        timestamps = data_str.split(\" \")\n",
    "        timestamps = [int(timestamp) for timestamp in timestamps]\n",
    "        time_measurement_row.append(timestamps)\n",
    "        \n",
    "    timestamps_data_matrix.append(visual_stimulus_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "        \n",
    "def compare_for_h0(arr_1, arr_2, alpha):\n",
    "    t, p = stats.ttest_ind(arr_1, arr_2)\n",
    "    if p > alpha:\n",
    "        return True, t, p\n",
    "    else:\n",
    "        return False, t, p\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_matrix = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    time_stamp_array = None\n",
    "    if len(timestamps_data_matrix) > dataset_idx:\n",
    "        time_stamp_array = timestamps_data_matrix[dataset_idx]\n",
    "    \n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        times = None\n",
    "        if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "            times = time_stamp_array[visual_idx]\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array[dataset_idx], stimulus_measurement,click_setting, time_stamps=times, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "        \n",
    "    heatmaps_matrix.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap_array in enumerate(heatmaps_matrix):\n",
    "    save_images(heatmap_array, \"./results/heatmaps/heatmaps/\" +  config_folder_prefix_array[idx], config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_heatmap_array = []\n",
    "avergae_heatmask_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    image = image_array[idx]\n",
    "    visual_measurements = visual_stimulus_data_matrix[idx]\n",
    "    time_measurements = None\n",
    "    if len(timestamps_data_matrix) > idx:\n",
    "        time_measurements = timestamps_data_matrix[idx]\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, visual_measurements, click_setting, 1.0, .0, time_measurements, should_copy=True)\n",
    "    average_heatmap_array.append(im)\n",
    "    avergae_heatmask_array.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap in enumerate(average_heatmap_array):\n",
    "    save_images([heatmap], \"./results/heatmaps/average_heatmap/\", config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.I.P.:to many clicks for dataset 3 datset 14\n"
     ]
    }
   ],
   "source": [
    "sequence_diagrams_matrix = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    #if time will be needed someday\n",
    "    #time_stamp_array = None\n",
    "    #if len(timestamps_data_matrix) > dataset_idx:\n",
    "    #    time_stamp_array = timestamps_data_matrix[dataset_idx]\n",
    "    \n",
    "    sequence_diagram_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        #if time will be needed someday\n",
    "        #times = None\n",
    "        #if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "        #    times = time_stamp_array[visual_idx]\n",
    "        try:\n",
    "            im = rEYEker.draw_vertical_line_diagram(image_array[dataset_idx], stimulus_measurement, should_copy=True)\n",
    "            sequence_diagram_array.append(im)\n",
    "        except:\n",
    "            #TODO\n",
    "            print(\"W.I.P.:\", end='')\n",
    "            print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "    sequence_diagrams_matrix.append(sequence_diagram_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sequence_diagram_array in enumerate(sequence_diagrams_matrix):\n",
    "    save_images(sequence_diagram_array, \"./results/sequence_diagrams/\"  +  config_folder_prefix_array[idx], config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Generate Code Flow diagramm</h2>\n",
    "\n",
    "<h4> User rEYEke_COdeFlow.ipynb to create the corresponding excel sheets </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>7. Analyse average of Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.1 Helper Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_displots(folder, indexing_array, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    indexing_array: how to index into the dataframe\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for idx, dataframe in enumerate(df_array):\n",
    "        values = dataframe[indexing_array[idx]].values.astype(float)\n",
    "        sns_plot = sns.displot(data=values, kde=True)\n",
    "        sns_plot.savefig(folder + config_image_prefix_array[idx] + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_combined_displot(folder, x_axis, dataframe):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    x_axis:         value to use for x_axis\n",
    "    dataframe:      dataframe with \"Algorithm\" field\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.displot(data=dataframe, x=x_axis, hue=\"Algorithm\", kind=\"kde\")\n",
    "    sns_plot.savefig(folder + \"Combined_Displot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_barplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.barplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm', estimator=np.median)\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Barplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.boxplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Boxplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_violinplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.violinplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Violinplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_implots(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    for idx in range(len(config_algo_names)):\n",
    "        tmp_df = df_tmp[df_tmp[\"Algorithm\"] == config_algo_names[idx]]\n",
    "        sns_plot = sns.lmplot(data=tmp_df, x=x_axis, y=y_axis)\n",
    "        sns_plot.set(ylim=(0, None))\n",
    "        sns_plot.savefig(folder + config_algo_names[idx] + str(idx) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_combined_implot(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    sns_plot = sns.lmplot(data=df_tmp, x=x_axis, y=y_axis, hue=\"Algorithm\")\n",
    "    sns_plot.set(ylim=(0, None))\n",
    "    sns_plot.savefig(folder + \"Combined_Implot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.2 Response Time</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new Dataframe which holds all the response time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Response Time', 'Algorithm']\n",
    "data = []\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data.append([row[config_response_time_variable_array[idx]], config_algo_names[idx]])\n",
    "algo_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Save Displots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/responseTime/displots/\", config_response_time_variable_array, df_array)\n",
    "\n",
    "save_combined_displot(\"./results/responseTime/displots/\", \"Response Time\", algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/responseTime/barplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/responseTime/boxplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_violinplot(\"./results/responseTime/violinplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.3. Code Flow vs Visual Stimulus</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load daraframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "No sheet named <'values'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36msheet_by_name\u001b[1;34m(self, sheet_name)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             \u001b[0msheetx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sheet_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'values' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b3ab4f46b2c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msheet_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msheet_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msheet_code_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/code_flow/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msheet_code_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msheet_code_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    309\u001b[0m         )\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m     return io.parse(\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[0mDataFrame\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mExcel\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \"\"\"\n\u001b[1;32m--> 906\u001b[1;33m         return self._reader.parse(\n\u001b[0m\u001b[0;32m    907\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sheet_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# assume an integer if not a string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mget_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sheet_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36msheet_by_name\u001b[1;34m(self, sheet_name)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0msheetx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sheet_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No sheet named <%r>'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheetx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: No sheet named <'values'>"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "config_array = []\n",
    "code_flow_array = []\n",
    "\n",
    "for value in config_code_flow_datasheet_array:\n",
    "    sheet_config = pd.read_excel('./data/code_flow/' + value, sheet_name=\"config\")\n",
    "    sheet_config = sheet_config.astype('int32')\n",
    "    \n",
    "    sheet_code_flow = pd.read_excel('./data/code_flow/' + value, sheet_name=\"values\")\n",
    "    sheet_code_flow = sheet_code_flow.astype('int32')\n",
    "    \n",
    "    config_array.append(sheet_config)\n",
    "    code_flow_array.append(sheet_code_flow)\n",
    "\n",
    "# transform stimulus data into code lines\n",
    "visual_stimulus_code_flow_matrix = []\n",
    "\n",
    "for idx1, visual_stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    converted_to_lines_array = []\n",
    "    \n",
    "    for dataset in visual_stimulus_dataset:\n",
    "        converted_to_lines = []\n",
    "        \n",
    "        for (x, y) in dataset:\n",
    "            num = -1\n",
    "            \n",
    "            for idx2, tup in config_array[idx1].iterrows():\n",
    "                if is_in(y, tup):\n",
    "                    num = idx2\n",
    "            \n",
    "            converted_to_lines.append(num)\n",
    "            \n",
    "        converted_to_lines_array.append(converted_to_lines)\n",
    "        \n",
    "    visual_stimulus_code_flow_matrix.append(converted_to_lines_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for visual stimulus flow\n",
    "        \n",
    "visual_stimulus_flow_matrix = []\n",
    "\n",
    "for idx, visual_stimulus_code_flow_datasets in enumerate(visual_stimulus_code_flow_matrix):\n",
    "    sequence_array = []\n",
    "    multiplier_offset = 10**get_0_offset(len(config_array[idx]))\n",
    "    \n",
    "    for visual_stimulus_code_flow_dataset in visual_stimulus_code_flow_datasets:\n",
    "        sequence = []\n",
    "        \n",
    "        for start in range(len(visual_stimulus_code_flow_dataset)-1):\n",
    "            pre = visual_stimulus_code_flow_dataset[start]\n",
    "            post = visual_stimulus_code_flow_dataset[start+1]\n",
    "            #potential skip if pre and post is equal, may be useful\n",
    "            num = pre * multiplier_offset + post\n",
    "            sequence.append(num)\n",
    "            \n",
    "        sequence_array.append(sequence)\n",
    "        \n",
    "    visual_stimulus_flow_matrix.append(sequence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for code flow\n",
    "code_flow_sequence_array = []\n",
    "\n",
    "for code_flow_dataset in code_flow_array:\n",
    "    sequence = []\n",
    "    multiplier_offset = 10**get_0_offset(len(code_flow_dataset))\n",
    "    \n",
    "    for start in range(len(code_flow_dataset)-1):\n",
    "        pre = code_flow_dataset['code flow'][start]\n",
    "        post = code_flow_dataset['code flow'][start+1]\n",
    "        #potential skip if pre and post is equal, may be useful\n",
    "        num = pre * multiplier_offset + post\n",
    "        sequence.append(num)\n",
    "        \n",
    "    code_flow_sequence_array.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes\n",
    "similarity_matrix = []\n",
    "\n",
    "for idx, code_flow_sequence in enumerate(code_flow_sequence_array):\n",
    "    sim_data = []\n",
    "    for visual_stimulus_sequence in visual_stimulus_flow_matrix[idx]:\n",
    "        sim_data.append(difflib.SequenceMatcher(None, code_flow_sequence, visual_stimulus_sequence).ratio())\n",
    "        \n",
    "    similarity_matrix.append(sim_data)\n",
    "    \n",
    "cols = ['Similarity', 'Algorithm']\n",
    "data = []\n",
    "for idx in range(len(similarity_matrix)):\n",
    "    for score in similarity_matrix[idx]:\n",
    "        data.append([score, config_algo_names[idx]])\n",
    "\n",
    "df_similarity = pd.DataFrame(data, columns=cols)\n",
    "df_similarity_array = []\n",
    "for idx in range(len(code_flow_array)):\n",
    "    df = pd.DataFrame(df_similarity.loc[df_similarity['Algorithm'] == config_algo_names[idx]] ,columns=cols)\n",
    "    df = df.drop('Algorithm', axis=1)\n",
    "    df_similarity_array.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/codeFlowSimilarity/displots/\", [\"Similarity\"]*len(similarity_matrix), df_similarity_array)\n",
    "\n",
    "save_combined_displot(\"./results/codeFlowSimilarity/displots/\", \"Similarity\", df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/codeFlowSimilarity/barplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/codeFlowSimilarity/boxplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_violinplot(\"./results/codeFlowSimilarity/violinplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.4. Regression Code Flow and Response time</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_implots(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")\n",
    "save_combined_implot(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.5. Statistical Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statical_data(df_array, indexing_array, folder, name):\n",
    "    def highlight_signficant(s):\n",
    "        if s.name != '#':\n",
    "            is_sig = df_significance[s.name]\n",
    "            return ['background-color: green' if v else '' for v in is_sig]\n",
    "        else:\n",
    "            return ['' for v in s] \n",
    "    \n",
    "    mean_array = []\n",
    "    is_significant = []\n",
    "    t_value_response_time = []\n",
    "    p_value_response_time = []\n",
    "    ratio = []\n",
    "\n",
    "    for idx1, df1 in enumerate(df_array):\n",
    "        different_tmp = [config_algo_names[idx1]]\n",
    "        t_tmp = [config_algo_names[idx1]]\n",
    "        p_tmp = [config_algo_names[idx1]]\n",
    "        ratio_tmp = [config_algo_names[idx1]]\n",
    "    \n",
    "        for idx2, df2 in enumerate(df_array):\n",
    "            (different, t, p) = compare_for_h0(df1[indexing_array[idx1]].values, df2[indexing_array[idx2]],  config_alpha)\n",
    "            different_tmp.append(not different)\n",
    "            t_tmp.append(t)\n",
    "            p_tmp.append(p)\n",
    "            ratio_tmp.append(df1[indexing_array[idx1]].mean() / df2[indexing_array[idx2]].mean())\n",
    "        \n",
    "        is_significant.append(different_tmp)\n",
    "        t_value_response_time.append(t_tmp)\n",
    "        p_value_response_time.append(p_tmp)\n",
    "        ratio.append(ratio_tmp)\n",
    "        mean_array.append(df1[indexing_array[idx1]].mean())\n",
    "    \n",
    "    df_significance = pd.DataFrame(is_significant, columns=['#'] + config_algo_names)\n",
    "\n",
    "    df_t = pd.DataFrame(t_value_response_time, columns=['#'] + config_algo_names)\n",
    "    df_p = pd.DataFrame(p_value_response_time, columns=['#'] + config_algo_names)\n",
    "    df_ratio = pd.DataFrame(ratio, columns=['#'] + config_algo_names)\n",
    "    df_ratio = df_ratio.style.apply(highlight_signficant)\n",
    "    df_mean = pd.DataFrame([mean_array], columns=config_algo_names)\n",
    "\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = pd.ExcelWriter(folder + name + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    df_ratio.to_excel(writer, sheet_name='ratio col row', index=False)\n",
    "    df_mean.to_excel(writer, sheet_name='mean value', index=False)\n",
    "    df_significance.to_excel(writer, sheet_name='statistical difference', index=False)\n",
    "    df_p.to_excel(writer, sheet_name='p values', index=False)\n",
    "    df_t.to_excel(writer, sheet_name='t values', index=False)\n",
    "\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_visual = []\n",
    "for dataset_row in visual_stimulus_data_matrix:\n",
    "    tmp_len = []\n",
    "    for dataset in dataset_row:\n",
    "        tmp_len.append(len(dataset))\n",
    "    len_of_visual.append(tmp_len)\n",
    "    \n",
    "len_df_array = []\n",
    "for len_array in len_of_visual:\n",
    "    df = pd.DataFrame(len_array, columns=['len'])\n",
    "    len_df_array.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to len of measured visual stimulus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statical_data(df_array, config_response_time_variable_array, './results/excel/', 'TotalResponseTime')\n",
    "create_statical_data(len_df_array, ['len']*len(len_df_array), './results/excel/', 'NumberOfMeasurements')\n",
    "create_statical_data(df_similarity_array, ['Similarity']*len(df_similarity_array), './results/excel/', 'SimilarityToCodeFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>8. Areas of Interest </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8.1. Helper</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def save_aoi_sequences(folder, image, image_prefix, aoi_mask, aoi_names, visual_measurement_array):\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    color = []\n",
    "    \n",
    "    for idx, visual_measurement in enumerate(visual_measurement_array):\n",
    "        im = image.copy()\n",
    "        \n",
    "        x = [x for (x,y) in visual_measurement]\n",
    "        y = [y for (x,y) in visual_measurement]\n",
    "        \n",
    "        cats = [int(aoi_mask[y,x]) for (x,y) in visual_measurement]\n",
    "        classes = [aoi_names[idx] for idx in cats]\n",
    "\n",
    "        val = [idx for idx in aoi_names]\n",
    "        for value in classes:\n",
    "            val.append(value)\n",
    "        \n",
    "        classes = val\n",
    "        \n",
    "        df_classes = pd.DataFrame(classes, columns=[\"aois\"])\n",
    "        incremental_step = float(df_classes['aois'].value_counts().max()-1)/float(max(len(cats) - 1,1))\n",
    "        \n",
    "        y_val = [1+i*incremental_step for i in range(len(cats))]\n",
    "        x_val = cats\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(6,6))\n",
    "        \n",
    "        sns.countplot(x=\"aois\", data=df_classes, ax=ax1);\n",
    "        ax1.plot(x_val, y_val, '-o', linewidth=2, color='black');\n",
    "        ax1.set_xticklabels(ax1.get_xticklabels(),rotation=35, horizontalalignment='right')\n",
    "        \n",
    "        ax1.figure.savefig(folder + image_prefix + \"aoi_sequence_\" + str(idx) + \".png\")\n",
    "        ax_color = ax1\n",
    "        \n",
    "        bars = [r for r in ax_color.get_children() if type(r)==Rectangle]\n",
    "        colors = [c.get_facecolor() for c in bars[:-1]]\n",
    "        colors = [[r,g,b] for (r,g,b,a) in colors]\n",
    "        color= np.array(colors).astype(np.float32)\n",
    "        plt.close()\n",
    "    \n",
    "    return color\n",
    "\n",
    "def apply_aoi_mask(image, colors, aoi_mask):\n",
    "    im = image.copy()\n",
    "    for height in range(im.shape[0]):\n",
    "        for width in range(im.shape[1]):\n",
    "            im[height, width] = 0.4 * im[height, width] + 0.6 * colors[aoi_mask[height, width]]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8.1. Areas of Interest supervised </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.HeatmapHelpers as heathelpers\n",
    "\n",
    "aoi_df_array = []\n",
    "columns = [\"startHeight\", \"stopHeight\", \"startWidth\", \"stopWidth\", \"Name\"]\n",
    "\n",
    "for aoi_sheet in config_aoi_datasheet_array:\n",
    "    raw = pd.read_excel(\"./data/aoi_categorized/\" + aoi_sheet)\n",
    "    df = pd.DataFrame(raw, columns=columns)\n",
    "    aoi_df_array.append(df)\n",
    "    \n",
    "aoi_mask_array = []\n",
    "aoi_region_name_matrix = []\n",
    "\n",
    "for idx in range(len(aoi_df_array)):\n",
    "    image_shape = image_array[idx].shape[0], image_array[idx].shape[1]\n",
    "    aoi_mask = np.zeros(image_shape)\n",
    "    aoi_names = []\n",
    "    for inner_idx, row in aoi_df_array[idx].iterrows():\n",
    "        start_height = row[\"startHeight\"]\n",
    "        stop_height = row[\"stopHeight\"]\n",
    "        start_width = row[\"startWidth\"]\n",
    "        stop_width = row[\"stopWidth\"]\n",
    "        name = row[\"Name\"]\n",
    "        aoi_names.append(name)\n",
    "        aoi_names = list(dict.fromkeys(aoi_names))\n",
    "        aoi_mask[start_height:stop_height, start_width:stop_width] = aoi_names.index(name)\n",
    "        \n",
    "        \n",
    "    aoi_mask_array.append(aoi_mask.astype(int))\n",
    "    aoi_region_name_matrix.append(aoi_names)\n",
    "\n",
    "visual_stimulus_data_matrix[idx]\n",
    "used_color_matrix = []\n",
    "for idx in range(len(aoi_df_array)):\n",
    "    colors = save_aoi_sequences(\"./results/aois/supervised/\" + config_folder_prefix_array[idx], image_array[idx], config_image_prefix_array[idx], aoi_mask_array[idx], aoi_region_name_matrix[idx], visual_stimulus_data_matrix[idx])\n",
    "    used_color_matrix.append(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_visual_stimulus_matrix = []\n",
    "\n",
    "for idx, visual_stimulus_array in enumerate(visual_stimulus_data_matrix):\n",
    "    aoi_visual_stimulus_array = []\n",
    "    \n",
    "    for idx1, visual_stimulus in enumerate(visual_stimulus_array):\n",
    "        \n",
    "        aoi_field_array = [aoi_mask_array[idx][y,x] for (x,y) in visual_stimulus]\n",
    "        aoi_visual_stimulus_array.append(aoi_field_array)\n",
    "    \n",
    "    aoi_visual_stimulus_matrix.append(aoi_visual_stimulus_array)\n",
    "\n",
    "aoi_transition_tensor = []\n",
    "\n",
    "for idx, aoi_visual_stimulus_array in enumerate(aoi_visual_stimulus_matrix):\n",
    "    aoi_transition_matrix = np.zeros((len(aoi_region_name_matrix[idx]), len(aoi_region_name_matrix[idx])))\n",
    "    \n",
    "    for aoi_visul_stimulus in aoi_visual_stimulus_array:\n",
    "        for idx1 in range(len(aoi_visul_stimulus) - 1):\n",
    "            aoi_transition_matrix[aoi_visul_stimulus[idx1], aoi_visul_stimulus[idx1+1]] += 1\n",
    "            \n",
    "    aoi_transition_tensor.append(aoi_transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chord import Chord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "    <!--Chord - Python wrapper around d3-chord\n",
       "\n",
       "    This package enables the generation of Chord diagrams. They can be saved \n",
       "    directly to HTML files or displayed in a Jupyter Notebook output cell.\n",
       "\n",
       "    Copyright 2020, Dr. Shahin Rostami\n",
       "    http://shahinrostami.com\n",
       "    https://github.com/shahinrostami/chord\n",
       "    https://pypi.org/project/chord/\n",
       "    -->\n",
       "    <!--LICENSE\n",
       "    Chord (https://github.com/shahinrostami/chord) generates interactive chord diagrams.\n",
       "    Copyright (C) 2020  Dr. Shahin Rostami\n",
       "\n",
       "    This program is free software: you can redistribute it and/or modify\n",
       "    it under the terms of the GNU Affero General Public License as published\n",
       "    by the Free Software Foundation, either version 3 of the License, or\n",
       "    (at your option) any later version.\n",
       "\n",
       "    This program is distributed in the hope that it will be useful,\n",
       "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
       "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
       "    GNU Affero General Public License for more details.\n",
       "\n",
       "    You should have received a copy of the GNU Affero General Public License\n",
       "    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
       "    -->\n",
       "  \t<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\n",
       "    <title>Chord Diagram</title>\n",
       "    <!-- Google Fonts -->\n",
       "    <script src=\"https://d3js.org/d3.v5.min.js\"></script>\n",
       "    <link\n",
       "      href=\"https://fonts.googleapis.com/css?family=Lato:400,900\"\n",
       "      rel=\"stylesheet\"\n",
       "      type=\"text/css\"\n",
       "    />\n",
       "\n",
       "    <style>\n",
       "      .tippy-content {\n",
       "        font-family: \"Lato\", sans-serif;\n",
       "      }\n",
       "\n",
       "      #chart-20316a8b, #featured-chart-20316a8b {\n",
       "\n",
       "        font-size: 16px;\n",
       "        font-family: \"Lato\", sans-serif;\n",
       "        text-align: center;\n",
       "        fill: #454545;\n",
       "      }\n",
       "\n",
       "      #chart-20316a8b svg, #featured-chart-20316a8b svg {\n",
       "        max-width: 700.0px;\n",
       "      }\n",
       "\n",
       "      @media (min-width: 600px) {\n",
       "\t\t\t\t#chart-20316a8b{\n",
       "\t\t\t\t\tfont-size: 20px;\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "    </style>\n",
       "  </head>\n",
       "  <body>\n",
       "    <div id=\"chart-20316a8b\" class=\"chord\">\n",
       "    </div>\n",
       "    <script src=\"https://unpkg.com/@popperjs/core@2\"></script>\n",
       "    <script src=\"https://unpkg.com/tippy.js@6\"></script>\n",
       "    <script>\n",
       "      var script = document.createElement(\"script\");\n",
       "      script.type = \"text/javascript\";\n",
       "      script.src = \"https://d3js.org/d3.v5.min.js\";\n",
       "\n",
       "      script.onload = function () {\n",
       "\n",
       "        var script2 = document.createElement(\"script\");\n",
       "        script2.type = \"text/javascript\";\n",
       "        script2.src = \"https://datacrayon.com/assets/chord/script.js\";\n",
       "        script2.onload = function () {\n",
       "          margin = {\n",
       "          left: 100.0,\n",
       "          top: 100.0,\n",
       "          right: 100.0,\n",
       "          bottom: 100.0\n",
       "        };\n",
       "        width = Math.min(window.innerWidth, 700.0) - margin.left - margin.right;\n",
       "        height = Math.min(window.innerWidth, 700.0) - margin.top - margin.bottom;\n",
       "        innerRadius = Math.min(width, height) * 0.39;\n",
       "        outerRadius = innerRadius * 1.1;\n",
       "\n",
       "      tag_id = \"chart-20316a8b\";\n",
       "      padding = 0.5;\n",
       "      Names = ['main', 'Iterative definition', 'Pre calculation', 'Iteration Condition', 'Iteration Step', 'Return Result'];\n",
       "      colors = d3.schemeSet1;\n",
       "      opacityDefault = 0.8;\n",
       "      matrix = [[197.0, 29.0, 34.0, 4.0, 13.0, 3.0], [5.0, 14.0, 39.0, 4.0, 3.0, 0.0], [25.0, 19.0, 98.0, 46.0, 53.0, 0.0], [8.0, 1.0, 23.0, 30.0, 52.0, 3.0], [20.0, 2.0, 49.0, 33.0, 109.0, 34.0], [9.0, 0.0, 1.0, 1.0, 24.0, 1.0]];\n",
       "      wrap_labels = true;\n",
       "      credit = true\n",
       "      \n",
       "      ////////////////////////////////////////////////////////////\n",
       "      /////////// Create scale and layout functions //////////////\n",
       "      ////////////////////////////////////////////////////////////\n",
       "\n",
       "      var colors = d3\n",
       "        .scaleOrdinal()\n",
       "        .domain(d3.range(Names.length))\n",
       "        .range(colors);\n",
       "\n",
       "      //A \"custom\" d3 chord function that automatically sorts the order of the chords in such a manner to reduce overlap\n",
       "      var chord = customChordLayout()\n",
       "        .padding(padding)\n",
       "        .sortChords(d3.descending) //which chord should be shown on top when chords cross. Now the biggest chord is at the bottom\n",
       "        .matrix(matrix);\n",
       "\n",
       "      var arc = d3\n",
       "        .arc()\n",
       "        .innerRadius(innerRadius * 1.01)\n",
       "        .outerRadius(outerRadius);\n",
       "\n",
       "      var path = d3.ribbon().radius(innerRadius);\n",
       "\n",
       "      ////////////////////////////////////////////////////////////\n",
       "      ////////////////////// Create SVG //////////////////////////\n",
       "      ///////////////////////////////////////////////////////////\n",
       "\n",
       "      var svg = d3\n",
       "        .select(\"#\" + tag_id)\n",
       "        .append(\"svg\")\n",
       "        .attr(\n",
       "          \"viewBox\",\n",
       "          \"0 0 \" +\n",
       "            (width + margin.left + margin.right) +\n",
       "          \" \" +\n",
       "          (height + margin.top + margin.bottom)\n",
       "        )\n",
       "        .attr(\"preserveAspectRatio\", \"xMinYMin meet\")\n",
       "        .append(\"g\")\n",
       "        .attr(\n",
       "          \"transform\",\n",
       "          \"translate(\" +\n",
       "            (width / 2 + margin.left) +\n",
       "            \",\" +\n",
       "            (height / 2 + margin.top) +\n",
       "            \")\"\n",
       "        );\n",
       "\n",
       "        d3\n",
       "          .select(\"#\" + tag_id)\n",
       "          .append(\"span\")\n",
       "          .style(\"display\", \"block\")\n",
       "          .style(\"font-size\", \"12px\")\n",
       "          .style(\"text-align\", \"right\")\n",
       "          .style(\"font-family\", '\"Arial\", sans-serif')\n",
       "          .html('get <a href=\"https://m8.fyi/chord\">chord pro</a> [<a href=\"https://twitter.com/shahinrostami\">@ShahinRostami</a>]');\n",
       "\n",
       "        d3\n",
       "          .select(\"#\" + tag_id)\n",
       "          .select(\"span\")\n",
       "          .append(\"span\")\n",
       "          .style(\"font-size\", \"12px\")\n",
       "          .style(\"font-family\", '\"Arial\", sans-serif')\n",
       "          .html('<br>see more at <a href=\"https://DataCrayon.com\">DataCrayon.com</a>');\n",
       "        \n",
       "      ////////////////////////////////////////////////////////////\n",
       "      /////////////// Create the gradient fills //////////////////\n",
       "      ////////////////////////////////////////////////////////////\n",
       "\n",
       "      //Function to create the id for each chord gradient\n",
       "      function getGradID(d) {\n",
       "        return (\n",
       "          \"linkGrad-\" + tag_id + \"-\" + d.source.index + \"-\" + d.target.index\n",
       "        );\n",
       "      }\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "      //Create the gradients definitions for each chord\n",
       "      var grads = svg\n",
       "        .append(\"defs\")\n",
       "        .selectAll(\"linearGradient\")\n",
       "        .data(chord.chords())\n",
       "        .enter()\n",
       "        .append(\"linearGradient\")\n",
       "        .attr(\"id\", getGradID)\n",
       "        .attr(\"gradientUnits\", \"userSpaceOnUse\")\n",
       "        .attr(\"x1\", function (d, i) {\n",
       "          return (\n",
       "            innerRadius *\n",
       "            Math.cos(\n",
       "              (d.source.endAngle - d.source.startAngle) / 2 +\n",
       "                d.source.startAngle -\n",
       "                Math.PI / 2\n",
       "            )\n",
       "          );\n",
       "        })\n",
       "        .attr(\"y1\", function (d, i) {\n",
       "          return (\n",
       "            innerRadius *\n",
       "            Math.sin(\n",
       "              (d.source.endAngle - d.source.startAngle) / 2 +\n",
       "                d.source.startAngle -\n",
       "                Math.PI / 2\n",
       "            )\n",
       "          );\n",
       "        })\n",
       "        .attr(\"x2\", function (d, i) {\n",
       "          return (\n",
       "            innerRadius *\n",
       "            Math.cos(\n",
       "              (d.target.endAngle - d.target.startAngle) / 2 +\n",
       "                d.target.startAngle -\n",
       "                Math.PI / 2\n",
       "            )\n",
       "          );\n",
       "        })\n",
       "        .attr(\"y2\", function (d, i) {\n",
       "          return (\n",
       "            innerRadius *\n",
       "            Math.sin(\n",
       "              (d.target.endAngle - d.target.startAngle) / 2 +\n",
       "                d.target.startAngle -\n",
       "                Math.PI / 2\n",
       "            )\n",
       "          );\n",
       "        });\n",
       "\n",
       "      //Set the starting color (at 0%)\n",
       "      grads\n",
       "        .append(\"stop\")\n",
       "        .attr(\"offset\", \"0%\")\n",
       "        .attr(\"stop-color\", function (d) {\n",
       "          return colors(d.source.index);\n",
       "        });\n",
       "\n",
       "      //Set the ending color (at 100%)\n",
       "      grads\n",
       "        .append(\"stop\")\n",
       "        .attr(\"offset\", \"100%\")\n",
       "        .attr(\"stop-color\", function (d) {\n",
       "          return colors(d.target.index);\n",
       "        });\n",
       "\n",
       "      ////////////////////////////////////////////////////////////\n",
       "      ////////////////// Draw outer Arcs /////////////////////////\n",
       "      ////////////////////////////////////////////////////////////\n",
       "\n",
       "      var outerArcs = svg\n",
       "        .selectAll(\"g.group\")\n",
       "        .data(chord.groups)\n",
       "        .enter()\n",
       "        .append(\"g\")\n",
       "        .attr(\"class\", \"group\")\n",
       "        .on(\"mouseover\", fade(0.1, 1))\n",
       "        .on(\"mouseout\", fade(opacityDefault, opacityDefault));\n",
       "\n",
       "      outerArcs\n",
       "        .append(\"path\")\n",
       "        .style(\"fill\", function (d) {\n",
       "          return colors(d.index);\n",
       "        })\n",
       "        .attr(\"d\", arc)\n",
       "        .each(function (d, i) {\n",
       "          //Search pattern for everything between the start and the first capital L\n",
       "          var firstArcSection = /(^.+?)L/;\n",
       "\n",
       "          //Grab everything up to the first Line statement\n",
       "          var newArc = firstArcSection.exec(d3.select(this).attr(\"d\"))[1];\n",
       "          //Replace all the comma's so that IE can handle it\n",
       "          newArc = newArc.replace(/,/g, \" \");\n",
       "\n",
       "          //If the end angle lies beyond a quarter of a circle (90 degrees or pi/2)\n",
       "          //flip the end and start position\n",
       "          if (\n",
       "            (d.endAngle > (90 * Math.PI) / 180) &\n",
       "            (d.startAngle < (270 * Math.PI) / 180)\n",
       "          ) {\n",
       "            var startLoc = /M(.*?)A/, //Everything between the first capital M and first capital A\n",
       "              middleLoc = /A(.*?)0 0 1/, //Everything between the first capital A and 0 0 1\n",
       "              endLoc = /0 0 1 (.*?)$/; //Everything between the first 0 0 1 and the end of the string (denoted by $)\n",
       "            //Flip the direction of the arc by switching the start en end point (and sweep flag)\n",
       "            //of those elements that are below the horizontal line\n",
       "            var newStart = endLoc.exec(newArc)[1];\n",
       "            var newEnd = startLoc.exec(newArc)[1];\n",
       "            var middleSec = middleLoc.exec(newArc)[1];\n",
       "\n",
       "            //Build up the new arc notation, set the sweep-flag to 0\n",
       "            newArc = \"M\" + newStart + \"A\" + middleSec + \"0 0 0 \" + newEnd;\n",
       "          } //if\n",
       "\n",
       "          //Create a new invisible arc that the text can flow along\n",
       "          svg\n",
       "            .append(\"path\")\n",
       "            .attr(\"class\", \"hiddenArcs\")\n",
       "            .attr(\"id\", \"arc-\" + tag_id + \"-\" + i)\n",
       "            .attr(\"d\", newArc)\n",
       "            .style(\"fill\", \"none\");\n",
       "     });\n",
       "          ////////////////////////////////////////////////////////////\n",
       "          ////////////////// Append Names ////////////////////////////\n",
       "          ////////////////////////////////////////////////////////////\n",
       "\n",
       "          //Append the label names on the outside\n",
       "\n",
       "          if (wrap_labels) {\n",
       "            outerArcs\n",
       "              .append(\"text\")\n",
       "              .attr(\"class\", \"titles\")\n",
       "              .attr(\"dy\", function (d, i) {\n",
       "                return (d.endAngle > (90 * Math.PI) / 180) &\n",
       "                  (d.startAngle < (270 * Math.PI) / 180)\n",
       "                  ? 25\n",
       "                  : -16;\n",
       "              })\n",
       "              .append(\"textPath\")\n",
       "              .attr(\"startOffset\", \"50%\")\n",
       "              .style(\"text-anchor\", \"middle\")\n",
       "              .attr(\"xlink:href\", function (d, i) {\n",
       "                return \"#arc-\" + tag_id + \"-\" + i;\n",
       "              })\n",
       "              .text(function (d, i) {\n",
       "                return Names[i];\n",
       "              });\n",
       "          } else {\n",
       "            //Append the label names on the outside\n",
       "            outerArcs\n",
       "              .append(\"text\")\n",
       "              .each(function (d) {\n",
       "                d.angle = (d.startAngle + d.endAngle) / 2;\n",
       "              })\n",
       "              .attr(\"dy\", \".35em\")\n",
       "              .attr(\"class\", \"titles\")\n",
       "              .attr(\"text-anchor\", function (d) {\n",
       "                return d.angle > Math.PI ? \"end\" : null;\n",
       "              })\n",
       "              .attr(\"transform\", function (d) {\n",
       "                return (\n",
       "                  \"rotate(\" +\n",
       "                  ((d.angle * 180) / Math.PI - 90) +\n",
       "                  \")\" +\n",
       "                  \"translate(\" +\n",
       "                  (outerRadius + 10) +\n",
       "                  \")\" +\n",
       "                  (d.angle > Math.PI ? \"rotate(180)\" : \"\")\n",
       "                );\n",
       "              })\n",
       "              .text(function (d, i) {\n",
       "                return Names[i];\n",
       "              });\n",
       "          }\n",
       "\n",
       "          ////////////////////////////////////////////////////////////\n",
       "          ////////////////// Draw inner chords ///////////////////////\n",
       "          ////////////////////////////////////////////////////////////\n",
       "\n",
       "          svg\n",
       "            .selectAll(\"path.chord\")\n",
       "            .data(chord.chords)\n",
       "            .enter()\n",
       "            .append(\"path\")\n",
       "            .attr(\"class\", \"chord\")\n",
       "            .style(\"fill\", function (d) {\n",
       "              return \"url(#\" + getGradID(d) + \")\";\n",
       "            })\n",
       "            .style(\"opacity\", opacityDefault)\n",
       "            .attr(\"d\", path)\n",
       "            .on(\"mouseover\", mouseoverChord())\n",
       "            .on(\"mouseout\", mouseoutChord(opacityDefault, opacityDefault));\n",
       "   \n",
       "      ////////////////////////////////////////////////////////////\n",
       "      ////////////////// Extra Functions /////////////////////////\n",
       "      ////////////////////////////////////////////////////////////\n",
       "\n",
       "      //Returns an event handler for fading a given chord group.\n",
       "      function fade(opacityIn, opacityOut) {\n",
       "        return function (d, i) {\n",
       "          d3.select(this.ownerSVGElement)\n",
       "            .selectAll(\"path.chord\")\n",
       "            .filter(function (d) {\n",
       "              return d.source.index !== i && d.target.index !== i;\n",
       "            })\n",
       "            .transition()\n",
       "            .style(\"opacity\", opacityIn);\n",
       "\n",
       "          d3.select(this.ownerSVGElement)\n",
       "            .selectAll(\"path.chord\")\n",
       "            .filter(function (d) {\n",
       "              return d.source.index == i || d.target.index == i;\n",
       "            })\n",
       "            .transition()\n",
       "            .style(\"opacity\", opacityOut);\n",
       "\n",
       "            \n",
       "        };\n",
       "      } //fade\n",
       "\n",
       "      //Highlight hovered over chord\n",
       "      function mouseoverChord() {\n",
       "        return function (d, i) {\n",
       "\n",
       "        d3.select(this.ownerSVGElement)\n",
       "          .selectAll(\"path.chord\")\n",
       "          .transition()\n",
       "          .style(\"opacity\", 0.1);\n",
       "        //Show hovered over chord with full opacity\n",
       "        d3.select(this).transition().style(\"opacity\", 1);\n",
       "\n",
       "        tippy_content = \"<span style='font-weight:900'>\" +\n",
       "            Names[d.source.index] +\n",
       "            \"</span> and <span style='font-weight:900'>\" +\n",
       "            Names[d.target.index] +\n",
       "            \"</span><br>occur together in <span style='font-weight:900'>\" +\n",
       "            d.source.value +\n",
       "            \"</span> instances\";\n",
       "   \n",
       "        if(this._tippy == null)\n",
       "        {\n",
       "          tippy(this, {\n",
       "            allowHTML: true,\n",
       "            followCursor: true,\n",
       "            content: tippy_content,\n",
       "            size: \"large\",\n",
       "            arrow: true,\n",
       "          });\n",
       "        }\n",
       "\n",
       "        };\n",
       "        \n",
       "      } //fade\n",
       "\n",
       "      //Bring all chords back to default opacity\n",
       "      function mouseoutChord(opacityIn, opacityOut) {\n",
       "        return function (d, i) {\n",
       "        d3.select(this.ownerSVGElement)\n",
       "          .selectAll(\"path.chord\")\n",
       "          .transition()\n",
       "          .style(\"opacity\", opacityOut);\n",
       "        };\n",
       "        //Set opacity back to default for all\n",
       "      } //function mouseoutChord\n",
       "\n",
       "\n",
       "        };\n",
       "        document.body.appendChild(script2);\n",
       "      };\n",
       "\n",
       "      document.body.appendChild(script);\n",
       "    </script>\n",
       "    <script></script>\n",
       "  </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Chord(aoi_transition_tensor[1].astype(int).tolist() ,aoi_region_name_matrix[1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8.2. Areas of Interest unsupervised</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to analyze areas of interests?\n",
    "\n",
    "1. [x] find max heat values or values above a treshhold\n",
    "    1. [x] split to large areas by a certain treshhold\n",
    "    2. [x] maybe create a bounding box of them and analyze them by prio for better computation time\n",
    "        1. [x] fix aois to lines, mybe to columns if the works seems useful for an algorithm\n",
    "\n",
    "2. [x] analyse how to jump between different regions of interests\n",
    "    1. [x] categorize just hot areas as aois\n",
    "    2. [x] categorize everything as aois\n",
    "    %% 3. [ ] list how the code flow jumps between theese regions\n",
    "\n",
    "3. [ ] analyse all the data for a mean and statical signifance\n",
    "    1. [ ] maybe implement gernerialized string mean algorithm for medium jumps (NP complte)\n",
    "    2. [ ] maybe use the same as in the code flow [#todo also implement genrerilized string mean for code flow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.HeatmapHelpers as heathelpers\n",
    "\n",
    "treshhold = 0.25\n",
    "chunk_width = 12\n",
    "value = 1.0 / treshhold\n",
    "upper_limit = 0.2\n",
    "\n",
    "shape = average_heatmap_array[0].shape[0], average_heatmap_array[0].shape[1]\n",
    "\n",
    "data = np.array(avergae_heatmask_array[0])\n",
    "data = np.reshape(data, shape)\n",
    "data = np.rint(data * value) / value\n",
    "data[data < upper_limit] = 0.0\n",
    "\n",
    "tmp = data.flatten().tolist()\n",
    "im = image_array[0].copy()\n",
    "heathelpers.draw_heat(im, tmp)\n",
    "\n",
    "imgplot0 = plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = average_heatmap_array[0].shape[0], average_heatmap_array[0].shape[1]\n",
    "horizontal_data = np.zeros(shape)\n",
    "\n",
    "for height_idx in range(shape[0]):\n",
    "    for val in range(0, shape[1], chunk_width):\n",
    "        max_val = data[height_idx, val:(val+chunk_width)].max()\n",
    "        horizontal_data[height_idx, val:(val+chunk_width)] = max_val\n",
    "\n",
    "heat_mask = horizontal_data.flatten().tolist()\n",
    "img = image_array[0].copy()\n",
    "heathelpers.draw_heat(img, heat_mask)\n",
    "\n",
    "imgplot0 = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = average_heatmap_array[0].shape[0], average_heatmap_array[0].shape[1]\n",
    "line_data = np.zeros(shape)\n",
    "\n",
    "for _idx, row in config_array[0].iterrows():\n",
    "    low = row[\"start\"]\n",
    "    high = row[\"stop\"] + 1\n",
    "    for val in range(0, shape[1], chunk_width):\n",
    "        max_val = data[low:high, val:(val+chunk_width)].max()\n",
    "        line_data[low:high, val:(val+chunk_width)] = max_val\n",
    "\n",
    "heat_mask = line_data.flatten().tolist()\n",
    "im = image_array[0].copy()\n",
    "heathelpers.draw_heat(im, heat_mask)\n",
    "\n",
    "imgplot0 = plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for (x,y) in visual_stimulus_data_matrix[0][0]]\n",
    "y = [y for (x,y) in visual_stimulus_data_matrix[0][0]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(im)\n",
    "ax.plot(x, y, ':o', linewidth=1, color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8));\n",
    "ax.set_ylim((0, 416))\n",
    "ax.set_xlim((0, 870))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.imshow(image_array[0])\n",
    "line, = ax.plot([], [], \"k-x\", lw=2)\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "x_glob = np.array([x for (x,y) in visual_stimulus_data_matrix[0][0]])\n",
    "y_glob = np.array([y for (x,y) in visual_stimulus_data_matrix[0][0]])\n",
    "\n",
    "len_value = len(x_glob)\n",
    "\n",
    "def animate(i):\n",
    "    low = max(0, i-16)\n",
    "    x = x_glob[low:i]\n",
    "    y = y_glob[low:i]\n",
    "\n",
    "    image = rEYEker.draw_shape_heat_map(image_array[0], visual_stimulus_data_matrix[0][0], click_setting, min_idx=low, max_idx=i, should_copy=True)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    #line.set_data(x,y)\n",
    "    return (line,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len_value, interval=100, blit=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "shape = (image_array[0].shape[0], image_array[0].shape[1])\n",
    "categorize_matrix = np.full(shape, -1)\n",
    "\n",
    "def get_adjacent(x, y, shape):\n",
    "    result = []\n",
    "    if x-1 >= 0:\n",
    "        result.append((x-1,y))\n",
    "    if x+1 < shape[0]:\n",
    "        result.append((x+1,y))\n",
    "    if y-1 >= 0:\n",
    "        result.append((x,y-1))\n",
    "    if y+1 < shape[1]:\n",
    "        result.append((x,y+1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def bfs_fill(start_x, start_y, cat_matrix, heat_mask, cat_value):\n",
    "    q = Queue()\n",
    "    value = heat_mask[start_x][start_y]\n",
    "    cat_matrix[start_x][start_y] = cat_value\n",
    "    q.put((start_x, start_y))\n",
    "    \n",
    "    while not q.empty():\n",
    "        (x,y) = q.get()\n",
    "        adjacent_array = get_adjacent(x, y, cat_matrix.shape)\n",
    "        for (ad_x, ad_y) in adjacent_array:\n",
    "            if cat_matrix[ad_x][ad_y] == -1 and heat_mask[ad_x][ad_y] == value:\n",
    "                cat_matrix[ad_x][ad_y] = cat_value\n",
    "                q.put((ad_x, ad_y))\n",
    "    \n",
    "cat_value = 0\n",
    "for x in range(shape[0]):\n",
    "    for y in range(shape[1]):\n",
    "        if categorize_matrix[x][y] == -1:\n",
    "            bfs_fill(x, y, categorize_matrix, line_data, cat_value)\n",
    "            cat_value += 1\n",
    "            \n",
    "aoi_mask = categorize_matrix.astype(int)\n",
    "aoi_names = [str(idx) for idx in range(cat_value)]\n",
    "\n",
    "colors = save_aoi_sequences(\"./results/aois/unsupervised/\" + config_folder_prefix_array[0], image_array[0], config_image_prefix_array[0], aoi_mask, aoi_names, visual_stimulus_data_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "im = image_array[0].copy()\n",
    "\n",
    "for height in range(im.shape[0]):\n",
    "    for width in range(im.shape[1]):\n",
    "        im[height, width] = 0.4 * im[height, width] + 0.6 * colors[categorize_matrix[height, width]]\n",
    "\n",
    "ax.imshow(im)\n",
    "ax.plot(x, y, ':', linewidth=2, color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
