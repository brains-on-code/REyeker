{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_prefix = ['BR', 'BI', 'TR', 'TI']\n",
    "\n",
    "config_algo_names = ['BinarySearch', 'BubbleSort', 'Factorial', 'Fibonacci', 'IntegerBinary', 'MultiplyMatrix', 'PrimeFactors', 'ReverseString']\n",
    "\n",
    "config_id_variable = \"CASE\"\n",
    "\n",
    "config_answer_variables = [\n",
    "    ['A310_01', 'A414_01', 'A214_01', 'A106_01'],\n",
    "    ['BR02_01', 'BI02_01', 'TR02_01', 'TI02_01'],\n",
    "    ['BR06_01', 'BI06_01', 'TR06_01', 'TI06_01'],\n",
    "    ['BR10_01', 'BI10_01', 'TR10_01', 'TI10_01'],\n",
    "    ['A406_01', 'A302_01', 'A102_01', 'A206_01'],\n",
    "    ['A210_01', 'A114_01', 'A314_01', 'A402_01'],\n",
    "    ['A110_01', 'A202_01', 'A410_01', 'A306_01'],\n",
    "    ['BR14_01', 'BI14_01', 'TR14_01', 'TI14_01'],\n",
    "]\n",
    "\n",
    "config_time_variables = [\n",
    "    ['TIME049','TIME070','TIME036','TIME015'],\n",
    "    ['TIME021','TIME055','TIME005','TIME038'],\n",
    "    ['TIME006','TIME040','TIME025','TIME061'],\n",
    "    ['TIME059','TIME023','TIME042','TIME008'],\n",
    "    ['TIME066','TIME051','TIME017','TIME032'],\n",
    "    ['TIME034','TIME019','TIME053','TIME064'],\n",
    "    ['TIME013','TIME030','TIME068','TIME047'],\n",
    "    ['TIME044','TIME010','TIME057','TIME027'],\n",
    "]\n",
    "\n",
    "config_click_variables = [\n",
    "    ['A319_01', 'A420_01', 'A220_01', 'A118_01'],\n",
    "    ['BR18_01', 'BI18_01', 'TR18_01', 'TI18_01'],\n",
    "    ['BR19_01', 'BI19_01', 'TR19_01', 'TI19_01'],\n",
    "    ['BR20_01', 'BI20_01', 'TR20_01', 'TI20_01'],\n",
    "    ['A418_01', 'A317_01', 'A117_01', 'A218_01'],\n",
    "    ['A219_01', 'A120_01', 'A320_01', 'A417_01'],\n",
    "    ['A119_01', 'A217_01', 'A419_01', 'A318_01'],\n",
    "    ['BR21_01', 'BI21_01', 'TR21_01', 'TI21_01']\n",
    "]\n",
    "\n",
    "\n",
    "config_answer_patterns = [\n",
    "    ['.*3.*', '.*3.*', '.*3.*', '.*3.*'],\n",
    "    ['.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*'],\n",
    "    ['.*6.*','.*6.*','.*120.*','.*120.*'],\n",
    "    ['.*2.*', '.*2.*','.*2.*','.*2.*'],\n",
    "    ['.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*'],\n",
    "    ['.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*'],\n",
    "    ['.*3.*5.*','.*3.*5.*','.*3.*5.*','.*3.*5.*'],\n",
    "    ['.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*']\n",
    "]\n",
    "\n",
    "\n",
    "config_datasheet = r'./Book5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = []\n",
    "raw = pd.read_excel(config_datasheet)\n",
    "\n",
    "# load data\n",
    "for row, _stuff in enumerate(config_algo_names):\n",
    "    df_array = []\n",
    "    for col, _stuff in enumerate(config_prefix):\n",
    "        df = pd.DataFrame(raw, columns = [config_id_variable, \n",
    "                                          config_answer_variables[row][col], \n",
    "                                          config_time_variables[row][col],\n",
    "                                          config_click_variables[row][col],])\n",
    "        df = df.iloc[1:]\n",
    "        df = df.dropna()\n",
    "        df_array.append(df)\n",
    "    df_matrix.append(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"id\", \"response_time\", \"correctness\", \"flag\", \"algo_name\", \"click_data\"]\n",
    "df_BU_R = pd.DataFrame(columns=cols)\n",
    "df_BU_I = pd.DataFrame(columns=cols)\n",
    "df_TD_R = pd.DataFrame(columns=cols)\n",
    "df_TD_I = pd.DataFrame(columns=cols)\n",
    "\n",
    "for row_idx, df_row in enumerate(df_matrix):\n",
    "    algo_name = config_algo_names[row_idx]\n",
    "    for col, df in enumerate(df_row): \n",
    "        pattern = config_answer_patterns[row_idx][col]\n",
    "        regex = re.compile(pattern)\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            id_value =  row[\"CASE\"]\n",
    "            response_time = int(row[config_time_variables[row_idx][col]])\n",
    "            answer = row[config_answer_variables[row_idx][col]]\n",
    "            click_data = row[config_click_variables[row_idx][col]]\n",
    "            result = regex.match(str(answer))\n",
    "            correctness = False\n",
    "            \n",
    "            if result is not None:\n",
    "                correctness = True\n",
    "                \n",
    "            flag = \"\"\n",
    "            data = pd.DataFrame([[id_value, response_time, correctness, flag, algo_name, click_data]], columns=cols)\n",
    "                  \n",
    "            if col == 0:\n",
    "                df_BU_R = df_BU_R.append(data)\n",
    "            elif col == 1:\n",
    "                df_BU_I = df_BU_I.append(data)\n",
    "            elif col == 2:\n",
    "                df_TD_R = df_TD_R.append(data)\n",
    "            else:\n",
    "                df_TD_I = df_TD_I.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:[231.51572327044025, 231.475, 174.76073619631902, 241.48809523809524]\n",
      "stddev:[240.02251622611962, 237.2851944854811, 204.807372141252, 371.5223736316899]\n",
      "Before Outlier removal: 650\n"
     ]
    }
   ],
   "source": [
    "df_array_independent = [df_BU_R, df_BU_I, df_TD_R, df_TD_I]\n",
    "df_means = [float(df[[\"response_time\"]].mean()) for df in df_array_independent]\n",
    "df_stds = [float(df[[\"response_time\"]].std()) for df in df_array_independent]\n",
    "df_len_b4 = [len(df) for df in df_array_independent]\n",
    "\n",
    "print(\"means:\" + str(df_means))\n",
    "print(\"stddev:\" + str(df_stds))\n",
    "print(\"Before Outlier removal: \" + str(sum(df_len_b4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(df_array_independent):\n",
    "    mean = float(df_means[idx])\n",
    "    stddev = float(df_stds[idx])\n",
    "    for idx, row in df.iterrows():\n",
    "        response_time = row[\"response_time\"]\n",
    "        #if mean+1.5*stddev < response_time < mean+2*stddev:\n",
    "        #    row[\"flag\"] = \"notNormal\"\n",
    "        \n",
    "        if not(30 < response_time < mean+2*stddev):\n",
    "            row[\"flag\"] = \"outlier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers: 32\n"
     ]
    }
   ],
   "source": [
    "dfs_length = [len(df.loc[df[\"flag\"]==\"outlier\"]) for df in df_array_independent]\n",
    "print(\"Number of Outliers: \" + str(sum(dfs_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means without outliers: [187.34, 191.9346405228758, 128.8684210526316, 188.1840490797546]\n"
     ]
    }
   ],
   "source": [
    "df_means = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].mean()) for df in df_array_independent]\n",
    "df_stds = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].std()) for df in df_array_independent]\n",
    "df_len_after = [len(df.loc[df[\"flag\"]!=\"outlier\"]) for df in df_array_independent]\n",
    "\n",
    "df_deleted_amount = [df_len_b4[idx]-df_len_after[idx] for idx in range(len(df_len_after))]\n",
    "print(\"means without outliers: \" + str(df_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [df.loc[df[\"id\"]==711] for df in df_array_independent]\n",
    "#for df in dfs:\n",
    "#    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(df_array_independent):\n",
    "    df.loc[df[\"flag\"] == \"outlier\", \"response_time\"] = int(df_means[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant with the following number got deleted: 712. Because 4 where missing.\n",
      "Participant with the following number got deleted: 785. Because 3 where missing.\n"
     ]
    }
   ],
   "source": [
    "cols = [\"id\", \"response_time\", \"correctness\", \"flag\"]\n",
    "deleted = []\n",
    "\n",
    "for idx1, df in enumerate(df_array_independent):\n",
    "    for idx2, row in df.iterrows():\n",
    "        id_value = row[\"id\"]\n",
    "        entries_id_BU_R = df_BU_R.loc[(df_BU_R[\"id\"] == id_value) & (df_BU_R[\"flag\"] == \"outlier\")]\n",
    "        entries_id_BU_I = df_BU_I.loc[(df_BU_I[\"id\"] == id_value) & (df_BU_I[\"flag\"] == \"outlier\")] \n",
    "        entries_id_TD_R = df_TD_R.loc[(df_TD_R[\"id\"] == id_value) & (df_TD_R[\"flag\"] == \"outlier\")]\n",
    "        entries_id_TD_I = df_TD_I.loc[(df_TD_I[\"id\"] == id_value) & (df_TD_I[\"flag\"] == \"outlier\")]\n",
    "        \n",
    "        df_per_participant = entries_id_BU_R\n",
    "        df_per_participant = df_per_participant.append(entries_id_BU_I)\n",
    "        df_per_participant = df_per_participant.append(entries_id_TD_R)\n",
    "        df_per_participant = df_per_participant.append(entries_id_TD_I)\n",
    "        \n",
    "        number_of_outliers_per_participant = len(df_per_participant)\n",
    "        \n",
    "        if number_of_outliers_per_participant == 2:\n",
    "            \n",
    "            df_not_normal_id_BU_R = df_BU_R.loc[(df_BU_R[\"id\"] == id_value) & (df_BU_R[\"flag\"] == \"notNormal\")]\n",
    "            df_not_normal_id_BU_I = df_BU_I.loc[(df_BU_I[\"id\"] == id_value) & (df_BU_I[\"flag\"] == \"notNormal\")] \n",
    "            df_not_normal_id_TD_R = df_TD_R.loc[(df_TD_R[\"id\"] == id_value) & (df_TD_R[\"flag\"] == \"notNormal\")]\n",
    "            df_not_normal_id_TD_I = df_TD_I.loc[(df_TD_I[\"id\"] == id_value) & (df_TD_I[\"flag\"] == \"notNormal\")]\n",
    "            \n",
    "            number_of_not_normals = len(df_not_normal_id_BU_R) + len(df_not_normal_id_BU_I) + len(df_not_normal_id_TD_R) + len(df_not_normal_id_TD_I)\n",
    "            if number_of_not_normals > 0:\n",
    "                print(\"Participant with the following number got deleted: \" + str(id_value) + \". Because 2 where missing and \" + str(number_of_not_normals) + \" datapoints where not normal.\")\n",
    "                df_BU_R = df_BU_R.loc[df_BU_R[\"id\"]!=id_value]\n",
    "                df_BU_I = df_BU_I.loc[df_BU_I[\"id\"]!=id_value]\n",
    "                df_TD_R = df_TD_R.loc[df_TD_R[\"id\"]!=id_value]\n",
    "                df_TD_I = df_TD_I.loc[df_TD_I[\"id\"]!=id_value]\n",
    "        \n",
    "        elif number_of_outliers_per_participant > 2:\n",
    "            print(\"Participant with the following number got deleted: \" + str(id_value) + \". Because \" + str(number_of_outliers_per_participant) + \" where missing.\")\n",
    "            deleted.append(id_value)\n",
    "            df_BU_R = df_BU_R.loc[df_BU_R[\"id\"]!=id_value]\n",
    "            df_BU_I = df_BU_I.loc[df_BU_I[\"id\"]!=id_value]\n",
    "            df_TD_R = df_TD_R.loc[df_TD_R[\"id\"]!=id_value]\n",
    "            df_TD_I = df_TD_I.loc[df_TD_I[\"id\"]!=id_value]\n",
    "            \n",
    "df_array_independent = [df_BU_R, df_BU_I, df_TD_R, df_TD_I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712, 785]\n"
     ]
    }
   ],
   "source": [
    "print(deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted per Style: [4, 4, 4, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len_after2 = [len(df) for df in df_array_independent]\n",
    "df_deleted_amount = [df_len_b4[idx]-df_len_after2[idx] for idx in range(len(df_len_after2))]\n",
    "print(\"Deleted per Style: \" + str(df_deleted_amount))\n",
    "sum(df_len_after2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numer of total correct answers: [85, 93, 92, 109]\n",
      "numer of total answers: [155, 156, 159, 164]\n",
      "percentages of correct answers: [0.5483870967741935, 0.5961538461538461, 0.5786163522012578, 0.6646341463414634]\n"
     ]
    }
   ],
   "source": [
    "total_answers = [len(df) for df in df_array_independent]\n",
    "total_correct = [len(df.loc[df[\"correctness\"]==True]) for df in df_array_independent]\n",
    "percentage = [float(correct)/float(total) for correct, total in zip(total_correct, total_answers)]\n",
    "print(\"numer of total correct answers: \" + str(total_correct))\n",
    "print(\"numer of total answers: \" + str(total_answers))\n",
    "print(\"percentages of correct answers: \" + str(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "cols = [\"Subject\",\"ProgrammingStyle\", \"Comprehension\", \"ResponseTime\", \"Algorithm\", \"Flag\", \"Correctness\", \"ClickData\"]\n",
    "\n",
    "def fill(list_data, dataframe, coding_style, comprehension_style):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        response_time = row[\"response_time\"]\n",
    "        algorithm = row[\"algo_name\"]\n",
    "        flag = row[\"flag\"]\n",
    "        click_data = row[\"click_data\"]\n",
    "        correctness = row[\"correctness\"]\n",
    "        id = row[\"id\"]\n",
    "        list_data.append([id,coding_style, comprehension_style, response_time, algorithm, flag, correctness, click_data])\n",
    "\n",
    "data = []\n",
    "fill(data, df_BU_R, \"R\", \"BU\")\n",
    "fill(data, df_BU_I, \"I\", \"BU\")\n",
    "fill(data, df_TD_R, \"R\", \"TD\")\n",
    "fill(data, df_TD_I, \"I\", \"TD\")\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "df.to_excel(\"preprocessed.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(ProgrammingStyle)</th>\n",
       "      <td>1.278280e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.792881</td>\n",
       "      <td>0.005411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Comprehension)</th>\n",
       "      <td>1.248239e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.609738</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(ProgrammingStyle):C(Comprehension)</th>\n",
       "      <td>9.606846e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.856696</td>\n",
       "      <td>0.015811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>9.923926e+06</td>\n",
       "      <td>605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sum_sq     df         F    PR(>F)\n",
       "C(ProgrammingStyle)                   1.278280e+05    1.0  7.792881  0.005411\n",
       "C(Comprehension)                      1.248239e+05    1.0  7.609738  0.005981\n",
       "C(ProgrammingStyle):C(Comprehension)  9.606846e+04    1.0  5.856696  0.015811\n",
       "Residual                              9.923926e+06  605.0       NaN       NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols(\"ResponseTime ~ C(ProgrammingStyle) * C(Comprehension) * C(ProgrammingStyle):C(Comprehension)\", data=df.loc[df[\"Flag\"]!=\"outlier\"]).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
