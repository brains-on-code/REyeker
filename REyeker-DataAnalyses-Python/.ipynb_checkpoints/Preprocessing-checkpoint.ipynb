{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_prefix = ['BR', 'BI', 'TR', 'TI']\n",
    "\n",
    "config_algo_names = ['BinarySearch', 'BubbleSort', 'Factorial', 'Fibonacci', 'IntegerBinary', 'MultiplyMatrix', 'PrimeFactors', 'ReverseString']\n",
    "\n",
    "config_id_variable = \"CASE\"\n",
    "\n",
    "config_answer_variables = [\n",
    "    ['A310_01', 'A414_01', 'A214_01', 'A106_01'],\n",
    "    ['BR02_01', 'BI02_01', 'TR02_01', 'TI02_01'],\n",
    "    ['BR06_01', 'BI06_01', 'TR06_01', 'TI06_01'],\n",
    "    ['BR10_01', 'BI10_01', 'TR10_01', 'TI10_01'],\n",
    "    ['A406_01', 'A302_01', 'A102_01', 'A206_01'],\n",
    "    ['A210_01', 'A114_01', 'A314_01', 'A402_01'],\n",
    "    ['A110_01', 'A202_01', 'A410_01', 'A306_01'],\n",
    "    ['BR14_01', 'BI14_01', 'TR14_01', 'TI14_01'],\n",
    "]\n",
    "\n",
    "config_time_variables = [\n",
    "    ['TIME049','TIME070','TIME036','TIME015'],\n",
    "    ['TIME021','TIME055','TIME005','TIME038'],\n",
    "    ['TIME006','TIME040','TIME025','TIME061'],\n",
    "    ['TIME059','TIME023','TIME042','TIME008'],\n",
    "    ['TIME066','TIME051','TIME017','TIME032'],\n",
    "    ['TIME034','TIME019','TIME053','TIME064'],\n",
    "    ['TIME013','TIME030','TIME068','TIME047'],\n",
    "    ['TIME044','TIME010','TIME057','TIME027'],\n",
    "]\n",
    "\n",
    "config_click_variables = [\n",
    "    ['A319_01', 'A420_01', 'A220_01', 'A118_01'],\n",
    "    ['BR18_01', 'BI18_01', 'TR18_01', 'TI18_01'],\n",
    "    ['BR19_01', 'BI19_01', 'TR19_01', 'TI19_01'],\n",
    "    ['BR20_01', 'BI20_01', 'TR20_01', 'TI20_01'],\n",
    "    ['A418_01', 'A317_01', 'A117_01', 'A218_01'],\n",
    "    ['A219_01', 'A120_01', 'A320_01', 'A417_01'],\n",
    "    ['A119_01', 'A217_01', 'A419_01', 'A318_01'],\n",
    "    ['BR21_01', 'BI21_01', 'TR21_01', 'TI21_01']\n",
    "]\n",
    "\n",
    "\n",
    "config_answer_patterns = [\n",
    "    ['.*3.*', '.*3.*', '.*3.*', '.*3.*'],\n",
    "    ['.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*','.*3.*16.*23.*42.*61.*75.*536.*'],\n",
    "    ['.*6.*','.*6.*','.*120.*','.*120.*'],\n",
    "    ['.*2.*', '.*2.*','.*2.*','.*2.*'],\n",
    "    ['.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*','.*1.*0.*0.*0.*1.*'],\n",
    "    ['.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*','.*6.*6.*6.*12.*12.*12.*18.*18.*18.*'],\n",
    "    ['.*3.*5.*','.*3.*5.*','.*3.*5.*','.*3.*5.*'],\n",
    "    ['.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*','.*gnikcar[tT].*ey[eE].*']\n",
    "]\n",
    "\n",
    "\n",
    "config_datasheet = r'./Book5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = []\n",
    "raw = pd.read_excel(config_datasheet)\n",
    "\n",
    "# load data\n",
    "for row, _stuff in enumerate(config_algo_names):\n",
    "    df_array = []\n",
    "    for col, _stuff in enumerate(config_prefix):\n",
    "        df = pd.DataFrame(raw, columns = [config_id_variable, \n",
    "                                          config_answer_variables[row][col], \n",
    "                                          config_time_variables[row][col],\n",
    "                                          config_click_variables[row][col],])\n",
    "        df = df.iloc[1:]\n",
    "        df = df.dropna()\n",
    "        df_array.append(df)\n",
    "    df_matrix.append(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"id\", \"response_time\", \"correctness\", \"flag\", \"algo_name\", \"click_data\"]\n",
    "df_BU_R = pd.DataFrame(columns=cols)\n",
    "df_BU_I = pd.DataFrame(columns=cols)\n",
    "df_TD_R = pd.DataFrame(columns=cols)\n",
    "df_TD_I = pd.DataFrame(columns=cols)\n",
    "\n",
    "for row_idx, df_row in enumerate(df_matrix):\n",
    "    algo_name = config_algo_names[row_idx]\n",
    "    for col, df in enumerate(df_row): \n",
    "        pattern = config_answer_patterns[row_idx][col]\n",
    "        regex = re.compile(pattern)\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            id_value =  row[\"CASE\"]\n",
    "            response_time = int(row[config_time_variables[row_idx][col]])\n",
    "            answer = row[config_answer_variables[row_idx][col]]\n",
    "            click_data = row[config_click_variables[row_idx][col]]\n",
    "            result = regex.match(str(answer))\n",
    "            correctness = False\n",
    "            \n",
    "            if result is not None:\n",
    "                correctness = True\n",
    "                \n",
    "            flag = \"\"\n",
    "            data = pd.DataFrame([[id_value, response_time, correctness, flag, algo_name, click_data]], columns=cols)\n",
    "                  \n",
    "            if col == 0:\n",
    "                df_BU_R = df_BU_R.append(data)\n",
    "            elif col == 1:\n",
    "                df_BU_I = df_BU_I.append(data)\n",
    "            elif col == 2:\n",
    "                df_TD_R = df_TD_R.append(data)\n",
    "            else:\n",
    "                df_TD_I = df_TD_I.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_array_independent = [df_BU_R, df_BU_I, df_TD_R, df_TD_I]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for idx, df in enumerate(df_array_independent):\n",
    "    mean = float(df_means[idx])\n",
    "    stddev = float(df_stds[idx])\n",
    "    for idx, row in df.iterrows():\n",
    "        response_time = row[\"response_time\"]\n",
    "        #if mean+1.5*stddev < response_time < mean+2*stddev:\n",
    "        #    row[\"flag\"] = \"notNormal\"\n",
    "        \n",
    "        #todo under 10 and wrong result\n",
    "        \n",
    "        #nur korrekte behandeln, ohne ausreiÃŸer\n",
    "        \n",
    "        #bei allen outlier raus \n",
    "        if not(10 < response_time < mean+2*stddev):\n",
    "            row[\"flag\"] = \"outlier\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dfs_length = [len(df.loc[df[\"flag\"]==\"outlier\"]) for df in df_array_independent]\n",
    "print(\"Number of Outliers: \" + str(sum(dfs_length)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_means = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].mean()) for df in df_array_independent]\n",
    "df_stds = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].std()) for df in df_array_independent]\n",
    "df_len_after = [len(df.loc[df[\"flag\"]!=\"outlier\"]) for df in df_array_independent]\n",
    "\n",
    "df_deleted_amount = [df_len_b4[idx]-df_len_after[idx] for idx in range(len(df_len_after))]\n",
    "print(\"means without outliers: \" + str(df_means))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_means = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].mean()) for df in df_array_independent]\n",
    "df_stds = [float(df.loc[df[\"flag\"]!=\"outlier\"][[\"response_time\"]].std()) for df in df_array_independent]\n",
    "df_len_after = [len(df.loc[df[\"flag\"]!=\"outlier\"]) for df in df_array_independent]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for idx, df in enumerate(df_array_independent):\n",
    "    df.loc[df[\"flag\"] == \"outlier\", \"response_time\"] = int(df_means[idx])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cols = [\"id\", \"response_time\", \"correctness\", \"flag\"]\n",
    "deleted = []\n",
    "\n",
    "for idx1, df in enumerate(df_array_independent):\n",
    "    for idx2, row in df.iterrows():\n",
    "        id_value = row[\"id\"]\n",
    "        entries_id_BU_R = df_BU_R.loc[(df_BU_R[\"id\"] == id_value) & (df_BU_R[\"flag\"] == \"outlier\")]\n",
    "        entries_id_BU_I = df_BU_I.loc[(df_BU_I[\"id\"] == id_value) & (df_BU_I[\"flag\"] == \"outlier\")] \n",
    "        entries_id_TD_R = df_TD_R.loc[(df_TD_R[\"id\"] == id_value) & (df_TD_R[\"flag\"] == \"outlier\")]\n",
    "        entries_id_TD_I = df_TD_I.loc[(df_TD_I[\"id\"] == id_value) & (df_TD_I[\"flag\"] == \"outlier\")]\n",
    "        \n",
    "        df_per_participant = entries_id_BU_R\n",
    "        df_per_participant = df_per_participant.append(entries_id_BU_I)\n",
    "        df_per_participant = df_per_participant.append(entries_id_TD_R)\n",
    "        df_per_participant = df_per_participant.append(entries_id_TD_I)\n",
    "        \n",
    "        number_of_outliers_per_participant = len(df_per_participant)\n",
    "        \n",
    "        if number_of_outliers_per_participant == 2:\n",
    "            \n",
    "            df_not_normal_id_BU_R = df_BU_R.loc[(df_BU_R[\"id\"] == id_value) & (df_BU_R[\"flag\"] == \"notNormal\")]\n",
    "            df_not_normal_id_BU_I = df_BU_I.loc[(df_BU_I[\"id\"] == id_value) & (df_BU_I[\"flag\"] == \"notNormal\")] \n",
    "            df_not_normal_id_TD_R = df_TD_R.loc[(df_TD_R[\"id\"] == id_value) & (df_TD_R[\"flag\"] == \"notNormal\")]\n",
    "            df_not_normal_id_TD_I = df_TD_I.loc[(df_TD_I[\"id\"] == id_value) & (df_TD_I[\"flag\"] == \"notNormal\")]\n",
    "            \n",
    "            number_of_not_normals = len(df_not_normal_id_BU_R) + len(df_not_normal_id_BU_I) + len(df_not_normal_id_TD_R) + len(df_not_normal_id_TD_I)\n",
    "            if number_of_not_normals > 0:\n",
    "                print(\"Participant with the following number got deleted: \" + str(id_value) + \". Because 2 where missing and \" + str(number_of_not_normals) + \" datapoints where not normal.\")\n",
    "                df_BU_R = df_BU_R.loc[df_BU_R[\"id\"]!=id_value]\n",
    "                df_BU_I = df_BU_I.loc[df_BU_I[\"id\"]!=id_value]\n",
    "                df_TD_R = df_TD_R.loc[df_TD_R[\"id\"]!=id_value]\n",
    "                df_TD_I = df_TD_I.loc[df_TD_I[\"id\"]!=id_value]\n",
    "        \n",
    "        elif number_of_outliers_per_participant > 2:\n",
    "            print(\"Participant with the following number got deleted: \" + str(id_value) + \". Because \" + str(number_of_outliers_per_participant) + \" where missing.\")\n",
    "            deleted.append(id_value)\n",
    "            df_BU_R = df_BU_R.loc[df_BU_R[\"id\"]!=id_value]\n",
    "            df_BU_I = df_BU_I.loc[df_BU_I[\"id\"]!=id_value]\n",
    "            df_TD_R = df_TD_R.loc[df_TD_R[\"id\"]!=id_value]\n",
    "            df_TD_I = df_TD_I.loc[df_TD_I[\"id\"]!=id_value]\n",
    "            \n",
    "df_array_independent = [df_BU_R, df_BU_I, df_TD_R, df_TD_I]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_BU_R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4a83a2b81b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_BU_R\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"R\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_BU_I\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"I\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_TD_R\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"R\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TD\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_BU_R' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "cols = [\"Subject\",\"ProgrammingStyle\", \"Comprehension\", \"ResponseTime\", \"Algorithm\", \"Flag\", \"Correctness\", \"ClickData\"]\n",
    "\n",
    "def fill(list_data, dataframe, coding_style, comprehension_style):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        response_time = row[\"response_time\"]\n",
    "        algorithm = row[\"algo_name\"]\n",
    "        flag = row[\"flag\"]\n",
    "        click_data = row[\"click_data\"]\n",
    "        correctness = row[\"correctness\"]\n",
    "        id = row[\"id\"]\n",
    "        list_data.append([id,coding_style, comprehension_style, response_time, algorithm, flag, correctness, click_data])\n",
    "\n",
    "data = []\n",
    "fill(data, df_BU_R, \"R\", \"BU\")\n",
    "fill(data, df_BU_I, \"I\", \"BU\")\n",
    "fill(data, df_TD_R, \"R\", \"TD\")\n",
    "fill(data, df_TD_I, \"I\", \"TD\")\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "df.to_excel(\"./results/preprocessed.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
